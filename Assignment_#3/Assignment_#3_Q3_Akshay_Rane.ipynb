{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_preprocessing(train_dataframe, test_dataframe):\n",
    "    merged_dataset = [train_dataframe, test_dataframe]\n",
    "\n",
    "    deck_ship = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "    ports_ship = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "    genders = {\"male\": 0, \"female\": 1}\n",
    "    \n",
    "    mean_age = train_dataframe[\"Age\"].mean()\n",
    "    std_age = test_dataframe[\"Age\"].std()\n",
    "    \n",
    "    \n",
    "    for dataset in merged_dataset:\n",
    "        \n",
    "        dataset[\"p_relatives\"] = dataset[\"SibSp\"] + dataset[\"Parch\"]\n",
    "        dataset.loc[dataset[\"p_relatives\"] > 0, \"individual\"] = 0\n",
    "        dataset.loc[dataset[\"p_relatives\"] == 0, \"individual\"] = 1\n",
    "        dataset[\"individual\"] = dataset[\"individual\"].astype(int)\n",
    "        \n",
    "        \n",
    "        dataset[\"Cabin\"] = dataset[\"Cabin\"].fillna(\"U0\")\n",
    "        dataset[\"Deck_Pos\"] = dataset[\"Cabin\"].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "        dataset[\"Deck_Pos\"] = dataset[\"Deck_Pos\"].map(deck_ship)\n",
    "        dataset[\"Deck_Pos\"] = dataset[\"Deck_Pos\"].fillna(0)\n",
    "        dataset[\"Deck_Pos\"] = dataset[\"Deck_Pos\"].astype(int)\n",
    "        \n",
    "        \n",
    "        is_null = dataset[\"Age\"].isnull().sum()\n",
    "        rand_age_to_fill = np.random.randint(mean_age - std_age, mean_age + std_age, size = is_null)\n",
    "        age_column_copy = dataset[\"Age\"].copy()\n",
    "        age_column_copy[np.isnan(age_column_copy)] = rand_age_to_fill\n",
    "        dataset[\"Age\"] = age_column_copy\n",
    "        dataset[\"Age\"] = train_dataframe[\"Age\"].astype(int)\n",
    "        \n",
    "        \n",
    "        dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")\n",
    "        dataset[\"Embarked\"] = dataset[\"Embarked\"].map(ports_ship)\n",
    "        \n",
    "        dataset[\"Sex\"] = dataset[\"Sex\"].map(genders)\n",
    "        \n",
    "        dataset[\"Fare\"] = dataset[\"Fare\"].fillna(0)\n",
    "        dataset[\"Fare\"] = dataset[\"Fare\"].astype(int)\n",
    "        \n",
    "    \n",
    "    train_dataframe[\"Age\"].isnull().sum()\n",
    "    merged_dataset = [train_dataframe, test_dataframe]\n",
    "    \n",
    "    for dataset in merged_dataset:\n",
    "        #divide Age into Age Groups\n",
    "        dataset.loc[ dataset['Age'] <= 10, 'Age'] = 0\n",
    "        dataset.loc[(dataset['Age'] > 10) & (dataset['Age'] <= 20), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] > 20) & (dataset['Age'] <= 30), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] > 30) & (dataset['Age'] <= 40), 'Age'] = 3\n",
    "        dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 50), 'Age'] = 4\n",
    "        dataset.loc[(dataset['Age'] > 50) & (dataset['Age'] <= 60), 'Age'] = 5\n",
    "        dataset.loc[ dataset['Age'] > 60, 'Age'] = 6\n",
    "        \n",
    "        #divide Fare into Fare Groups\n",
    "        dataset.loc[ dataset['Fare'] <= 8, 'Fare'] = 0\n",
    "        dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 15), 'Fare'] = 1\n",
    "        dataset.loc[(dataset['Fare'] > 15) & (dataset['Fare'] <= 40), 'Fare']   = 2\n",
    "        dataset.loc[(dataset['Fare'] > 40) & (dataset['Fare'] <= 100), 'Fare']   = 3\n",
    "        dataset.loc[(dataset['Fare'] > 100) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "        dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"SibSp\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"SibSp\"], axis=1)\n",
    "    \n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"Parch\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"Parch\"], axis=1)\n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"p_relatives\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"p_relatives\"], axis=1)\n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"Cabin\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"Cabin\"], axis=1)\n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"Name\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"Name\"], axis=1)\n",
    "    \n",
    "    train_dataframe = train_dataframe.drop([\"Ticket\"], axis=1)\n",
    "    test_dataframe = test_dataframe.drop([\"Ticket\"], axis=1)\n",
    "\n",
    "    return train_dataframe,test_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perform_decision_tree_algorithm(train_dataframe, test_dataframe, max_depth, min_size):\n",
    "    \n",
    "    decision_tree = build_decision_tree(train_dataframe, max_depth, min_size)\n",
    "    predictions = []\n",
    "    for index,row in test_dataframe.iterrows():\n",
    "        prediction = predict(decision_tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "\n",
    "def build_decision_tree(train_dataframe, max_depth, min_size):\n",
    "    root_node , gini_index_columns, information_gain_columns  = perform_split(train_dataframe,performGain = 1)\n",
    "    display_ig_gini_table(gini_index_columns,information_gain_columns)\n",
    "    \n",
    "    split_root_node_recursively(root_node, max_depth, min_size, 1)\n",
    "    return root_node\n",
    "\n",
    "def perform_split(train_dataframe, performGain = 0):\n",
    "    \n",
    "    gini_index_columns = {}\n",
    "    information_gain_columns = {}\n",
    "    number_of_rows = len(train_dataframe)\n",
    "    \n",
    "    X_train = train_dataframe.drop(\"Survived\", axis=1)\n",
    "    Y_train = train_dataframe[\"Survived\"]\n",
    "    \n",
    "    class_labels = list(set(label[\"Survived\"] for index,label in train_dataframe.iterrows()))\n",
    "    \n",
    "    total_entropy = 0\n",
    "    column_entropy = 0\n",
    "\n",
    "    b_column_name, b_column_value, b_score, b_groups = 999, 999, 999, None\n",
    "    \n",
    "    number_of_columns = len(X_train.columns)\n",
    "\n",
    "    for column in X_train.columns:\n",
    "        \n",
    "        unique_value = []\n",
    "        for index, row in train_dataframe.iterrows():\n",
    "            \n",
    "            if row[column] in unique_value:\n",
    "                continue\n",
    "                \n",
    "            unique_value.append(row[column])    \n",
    "            groups = split(column, row[column], train_dataframe)\n",
    "            \n",
    "            gini_index = calculate_gini_index(groups, class_labels)\n",
    "            \n",
    "            if performGain == 1:\n",
    "                total_entropy = calculate_total_entropy(train_dataframe, class_labels, number_of_rows)\n",
    "                column_entropy = calculate_column_entropy(train_dataframe, column, class_labels, number_of_rows)\n",
    "            \n",
    "                information_gain_columns[column] = total_entropy - column_entropy\n",
    "                gini_index_columns[column] = gini_index\n",
    "            \n",
    "            if gini_index < b_score:\n",
    "                b_column_name, b_column_value, b_score, b_groups = column, row[column], gini_index, groups\n",
    "    \n",
    "    if performGain == 1:\n",
    "        return {'index':b_column_name, 'value':b_column_value, 'groups':b_groups}, gini_index_columns, information_gain_columns\n",
    "    else:\n",
    "        return {'index':b_column_name, 'value':b_column_value, 'groups':b_groups}\n",
    "        \n",
    "    \n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def split(column_index, value, train_dataframe):\n",
    "    \n",
    "    left_split = pd.DataFrame(columns=train_dataframe.columns)\n",
    "    right_split = pd.DataFrame(columns=train_dataframe.columns)\n",
    "    \n",
    "    for index, row in train_dataframe.iterrows():\n",
    "        if row[column_index] < value:\n",
    "            left_split = left_split.append(row)\n",
    "        else:\n",
    "            right_split = right_split.append(row)\n",
    "    \n",
    "    return left_split, right_split\n",
    "\n",
    "def calculate_gini_index(groups, class_labels):\n",
    "    total_instance_groups = 0.0\n",
    "    \n",
    "    for group in groups:\n",
    "        total_instance_groups = total_instance_groups +  len(group)\n",
    "    \n",
    "    gini_index = 0.0\n",
    "    \n",
    "    for group in groups:\n",
    "        group_size = float(len(group))\n",
    "        if group_size == 0:\n",
    "            continue\n",
    "            \n",
    "        score = 0.0\n",
    "        \n",
    "        for label in class_labels:\n",
    "            proportion = [row[\"Survived\"] for index,row in group.iterrows()].count(label) / group_size\n",
    "            score = score + proportion * proportion\n",
    "        \n",
    "        gini_index = gini_index + (1.0 - score) * (group_size / total_instance_groups)\n",
    "        \n",
    "    return gini_index\n",
    "\n",
    "def calculate_total_entropy(train_dataframe, class_labels , number_of_rows):\n",
    "    total_entropy = 0.0\n",
    "    \n",
    "    for label in class_labels:\n",
    "        total_entropy = total_entropy + (-(len(train_dataframe[train_dataframe['Survived'] == label])\\\n",
    "                                           /number_of_rows)*math.log2(len(train_dataframe[train_dataframe['Survived'] \\\n",
    "                                                                                          == label])/number_of_rows))\n",
    "    return total_entropy\n",
    "\n",
    "def calculate_column_entropy(train_dataframe,column_name,class_labels,number_of_rows):\n",
    "    column_entropy = 0\n",
    "    \n",
    "    unique_column_values = list(train_dataframe[column_name].unique())\n",
    "    \n",
    "    for column_value in unique_column_values:\n",
    "        for label in class_labels:\n",
    "            \n",
    "            probability_value = -len(train_dataframe[train_dataframe[column_name] == column_value])/number_of_rows\n",
    "            conditional_probability_value = len(train_dataframe[(train_dataframe['Survived'] == label) & (train_dataframe[column_name]\\\n",
    "                                                                       == column_value)])/len(train_dataframe[column_name] == column_value)\n",
    "            if conditional_probability_value != 0:\n",
    "                column_entropy = column_entropy + probability_value*(conditional_probability_value*math.log2(conditional_probability_value))\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    return column_entropy  \n",
    "\n",
    "def display_ig_gini_table(gini_index_columns,information_gain_columns):\n",
    "    print(\"%12s\\t%12s\\t%12s\"%(\"Column_Name\",\"Information_Gain\",\"Gini_Index\"))\n",
    "\n",
    "    for column_name, gain_value in information_gain_columns.items():\n",
    "        print(\"%12s\\t%12s\\t%12s\"% (column_name,gain_value,gini_index_columns[column_name]))\n",
    "    \n",
    "        \n",
    "\n",
    "def split_root_node_recursively(current_node, max_depth, min_size, depth):\n",
    "    left, right = current_node[\"groups\"]\n",
    "    del(current_node[\"groups\"])\n",
    "    \n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        if len(left) == 0:\n",
    "            current_node[\"left_tree\"] = current_node[\"right_tree\"] = create_leaf_node(right)\n",
    "        else:\n",
    "            current_node[\"left_tree\"] = current_node[\"right_tree\"] = create_leaf_node(left)\n",
    "            \n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        current_node[\"left_tree\"], current_node[\"right_tree\"] = create_leaf_node(left), create_leaf_node(right)\n",
    "        return\n",
    "\n",
    "    if len(left) <= min_size:\n",
    "        current_node[\"left_tree\"] = create_leaf_node(left)\n",
    "    else:\n",
    "        current_node[\"left_tree\"] = perform_split(left)\n",
    "        split_root_node_recursively(current_node[\"left_tree\"], max_depth, min_size, depth+1)\n",
    "\n",
    "    if len(right) <= min_size:\n",
    "        current_node[\"right_tree\"] = create_leaf_node(right)\n",
    "    else:\n",
    "        current_node[\"right_tree\"] = perform_split(right)\n",
    "        split_root_node_recursively(current_node[\"right_tree\"], max_depth, min_size, depth+1)\n",
    "\n",
    "def create_leaf_node(group):\n",
    "    classifier_count = [row[\"Survived\"] for index,row in group.iterrows()]\n",
    "    return max(set(classifier_count), key=classifier_count.count)\n",
    "    \n",
    "def predict(current_node, row):\n",
    "    \n",
    "    if row[current_node[\"index\"]] < current_node[\"value\"]:\n",
    "        if isinstance(current_node[\"left_tree\"], dict):\n",
    "            return predict(current_node[\"left_tree\"], row)\n",
    "        else:\n",
    "            return current_node[\"left_tree\"]\n",
    "    else:\n",
    "        if isinstance(current_node[\"right_tree\"], dict):\n",
    "            return predict(current_node[\"right_tree\"], row)\n",
    "        else:\n",
    "            return current_node[\"right_tree\"]\n",
    "\n",
    "def calculate_accuracy(ground_truth, predicted):\n",
    "    correct_prediction = 0\n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i] == predicted[i]:\n",
    "            correct_prediction = correct_prediction + 1\n",
    "    return correct_prediction / float(len(ground_truth)) * 100.0\n",
    "\n",
    "def perform_cross_validation(kfold_factor, train_dataframe, test_dataframe):\n",
    "    k_fold = KFold(n_splits=kfold_factor)\n",
    "    \n",
    "    X_train_dataframe = train_dataframe.drop(\"Survived\",axis = 1)\n",
    "    Y_train_dataframe = train_dataframe[[\"Survived\",\"PassengerId\"]]\n",
    "    \n",
    "    \n",
    "    X_column_values = X_train_dataframe.columns\n",
    "    \n",
    "    Y_column_values = Y_train_dataframe.columns\n",
    "    \n",
    "    X_train_dataframe = np.array(X_train_dataframe)\n",
    "    Y_train_dataframe = np.array(Y_train_dataframe)\n",
    "    \n",
    "    \n",
    "    X_shuffled_train , predictions_shuffled_train = shuffle(X_train_dataframe, Y_train_dataframe, random_state=0)\n",
    "    \n",
    "    accuracy_array = []\n",
    "    \n",
    "    for train_index, test_index in k_fold.split(X_shuffled_train):\n",
    "        y_train, y_test = predictions_shuffled_train[train_index], predictions_shuffled_train[test_index]\n",
    "       \n",
    "        X_train, X_test = X_shuffled_train[train_index], X_shuffled_train[test_index]\n",
    "       \n",
    "        \n",
    "        X_train = pd.DataFrame(data=X_train, columns=X_column_values, dtype =object)\n",
    "        y_train = pd.DataFrame(data=y_train, columns=Y_column_values, dtype =object)\n",
    "        \n",
    "    \n",
    "        train_dataframe_new = pd.merge(X_train, y_train, on=['PassengerId'])\n",
    "        train_dataframe_new = train_dataframe_new.drop([\"PassengerId\"], axis=1)\n",
    "        \n",
    "        X_test = pd.DataFrame(data=X_test, columns=X_column_values, dtype =object)\n",
    "        y_test = pd.DataFrame(data=y_test, columns=Y_column_values, dtype =object)\n",
    "        \n",
    "        test_dataframe_new = pd.merge(X_test, y_test, on=['PassengerId'])\n",
    "        test_dataframe_new = test_dataframe_new.drop([\"PassengerId\"], axis=1)\n",
    "        \n",
    "        \n",
    "        predictions = perform_decision_tree_algorithm(train_dataframe_new, test_dataframe_new, 5, 10)\n",
    "        accuracy = calculate_accuracy(y_test.Survived,predictions)\n",
    "        accuracy_array.append(accuracy)\n",
    "        \n",
    "    return max(accuracy_array)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Column_Name\tInformation_Gain\t  Gini_Index\n",
      "      Pclass\t0.13561408602252512\t0.4728214556242898\n",
      "         Sex\t0.11542259443956338\t0.4728214556242898\n",
      "         Age\t0.31059816660111794\t0.472624659198165\n",
      "        Fare\t0.270583356733349\t0.46836515146340624\n",
      "    Embarked\t0.07549237730376401\t0.4725294553682896\n",
      "  individual\t0.0021611946425970086\t0.45710021367402565\n",
      "    Deck_Pos\t0.15606448442091714\t0.4728214556242898\n",
      " Column_Name\tInformation_Gain\t  Gini_Index\n",
      "      Pclass\t0.14947117881045258\t0.42477930820473175\n",
      "         Sex\t0.11967384304062434\t0.32834858009734813\n",
      "         Age\t0.3062373267136913\t0.47362242711198665\n",
      "        Fare\t0.29025055037607894\t0.4717272961018218\n",
      "    Embarked\t0.07956638813608108\t0.4736870452836611\n",
      "  individual\t0.010689962025948962\t0.47386839087355836\n",
      "    Deck_Pos\t0.16762313000930895\t0.47386839087355836\n",
      " Column_Name\tInformation_Gain\t  Gini_Index\n",
      "      Pclass\t0.14250748924629808\t0.4386100384483681\n",
      "         Sex\t0.11793300748688373\t0.3364280260789595\n",
      "         Age\t0.3214377824874871\t0.4777148827922234\n",
      "        Fare\t0.2863385411664642\t0.4765141794236718\n",
      "    Embarked\t0.07995181771326965\t0.47920460945183635\n",
      "  individual\t0.009351678908743\t0.4793211230425144\n",
      "    Deck_Pos\t0.16024471478300262\t0.4793211230425144\n",
      " Column_Name\tInformation_Gain\t  Gini_Index\n",
      "      Pclass\t0.14471155364336485\t0.43656441716311906\n",
      "         Sex\t0.11586428031943563\t0.33336899700092576\n",
      "         Age\t0.3149236023653812\t0.4732651466484596\n",
      "        Fare\t0.2775168167566717\t0.4714439663711065\n",
      "    Embarked\t0.07459109036814693\t0.4738640321810027\n",
      "  individual\t0.007287659290760029\t0.47386839087355836\n",
      "    Deck_Pos\t0.1562555769069276\t0.47386839087355836\n",
      " Column_Name\tInformation_Gain\t  Gini_Index\n",
      "      Pclass\t0.1345011697201528\t0.4298513014032994\n",
      "         Sex\t0.1078654513937588\t0.3335428816877998\n",
      "         Age\t0.2987563449170003\t0.4620601975642487\n",
      "        Fare\t0.26734055491734554\t0.4597854420785698\n",
      "    Embarked\t0.0740433570202017\t0.46411949881404707\n",
      "  individual\t-0.0016925758244751288\t0.4641195666926976\n",
      "    Deck_Pos\t0.15788816839162578\t0.4641195666926976\n",
      "Accuracy: 85.393%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataframe = pd.read_csv(\"train.csv\")\n",
    "test_dataframe = pd.read_csv(\"test.csv\")\n",
    "Y_test = pd.read_csv(\"gender_submission.csv\")\n",
    "test_dataframe = pd.merge(test_dataframe, Y_test, on=['PassengerId'])\n",
    "train_dataframe, test_dataframe = perform_preprocessing(train_dataframe,test_dataframe)\n",
    "\n",
    "# cross validation remaining\n",
    "\n",
    "accuracy = perform_cross_validation(5, train_dataframe, test_dataframe)\n",
    "print(\"Accuracy: %.3f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
