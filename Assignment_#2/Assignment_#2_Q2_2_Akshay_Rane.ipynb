{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['id','category']\n",
    "for i in range(0,30):\n",
    "    attr_label = 'attr' + str(i+1)\n",
    "    column_list.append(attr_label)\n",
    "\n",
    "data_pgm = pd.read_csv(\"wdbc.data\" ,  sep=\",\", names=column_list)\n",
    "\n",
    "y_data_pgm = data_pgm['category']\n",
    "\n",
    "X_data_pgm = data_pgm.drop(['id','category'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 48.40%\n",
      "Precision: 29.77%\n",
      "Accuracy: 52.15%\n"
     ]
    }
   ],
   "source": [
    "def signmoid_funtion(a):\n",
    "    sigmoid_value = 0\n",
    "    sigmoid_value = 1 / (1 + np.exp(-a))    \n",
    "    return sigmoid_value\n",
    "\n",
    "def prediction(weight, imput_data, w0,probablity_of_M, probablity_of_B, \\\n",
    "               mean_vectors_classes, count_vectors_classes):\n",
    "    first_term = np.dot(weight.T,imput_data)\n",
    "    argument_a = first_term + w0\n",
    "    return signmoid_funtion(argument_a.astype(float))\n",
    "\n",
    "def determine_covariance(input_data,mean_vectors_classes,count_vectors_classes):\n",
    "    \n",
    "    count_m = count_vectors_classes[\"M\"]\n",
    "    count_b = count_vectors_classes[\"B\"]\n",
    "    total_count = count_m + count_b\n",
    "    \n",
    "    column_length = input_data.shape[1]\n",
    "    \n",
    "    for index, row in input_data.iterrows():\n",
    "        s1 = s2 = np.zeros((column_length-1,1), dtype=object)\n",
    "        \n",
    "        row_matrix = row.values[0:(column_length-1)].reshape(column_length-1,1)\n",
    "        category_mean_vector = mean_vectors_classes[row.category]\n",
    "        \n",
    "        if \"M\" == row.category:\n",
    "            category_mean_vector =  np.reshape(category_mean_vector, (column_length-1, 1))\n",
    "            diff_matrix = row_matrix - category_mean_vector\n",
    "            s1 = s1 + np.dot(diff_matrix,diff_matrix.T)\n",
    "        else:\n",
    "            category_mean_vector =  np.reshape(category_mean_vector, (column_length-1, 1))\n",
    "            diff_matrix = row_matrix - category_mean_vector\n",
    "            s2 = s2 + np.dot(diff_matrix,diff_matrix.T)\n",
    "    \n",
    "    return (((s1)/total_count))+(((s2)/total_count))\n",
    "\n",
    "def determine_coefficients(probablity_of_M,probablity_of_B,merge_data_frame, \\\n",
    "                           mean_vectors_classes,count_vectors_classes):\n",
    "    \n",
    "    covariance_matrix = determine_covariance(merge_data_frame,mean_vectors_classes,count_vectors_classes)\n",
    "   \n",
    "    mean_vector_class_m = mean_vectors_classes[\"M\"]\n",
    "    mean_vector_class_b = mean_vectors_classes[\"B\"]\n",
    "    \n",
    "    mean_vector_class_m = np.reshape(mean_vector_class_m, (merge_data_frame.shape[1] -1, 1))\n",
    "    mean_vector_class_b= np.reshape(mean_vector_class_b, (merge_data_frame.shape[1] -1 , 1))\n",
    "\n",
    "\n",
    "    covariance_matrix_inv = np.linalg.inv(covariance_matrix.astype(\"float\"))\n",
    "    \n",
    "    w =  covariance_matrix_inv.dot(( mean_vector_class_m- mean_vector_class_b))\n",
    "    \n",
    "    w0 = ((-1) * mean_vector_class_m.T.dot(covariance_matrix).dot(mean_vector_class_m)) + \\\n",
    "    ((1) * mean_vector_class_b.T.dot(covariance_matrix).dot(mean_vector_class_b)) + \\\n",
    "    np.log(probablity_of_M/probablity_of_B)\n",
    "   \n",
    "    return w,w0\n",
    "\n",
    "def perform_cross_validation(kfold_factor, X_data_pgm, predictions_pgm):\n",
    "    \n",
    "    # 1 is M\n",
    "    # 2 is B\n",
    "    k_fold = KFold(n_splits=kfold_factor)\n",
    "    X_pgm = np.array(X_data_pgm)\n",
    "    X_shuffled_pgm , predictions_shuffled_pgm = shuffle(X_pgm, predictions_pgm, random_state=0)\n",
    "    \n",
    "    accuracy_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    \n",
    "    for train_index, test_index in k_fold.split(X_shuffled_pgm):\n",
    "        X_train_pgm, X_test_pgm = X_shuffled_pgm[train_index], X_shuffled_pgm[test_index]\n",
    "        y_train_pgm, y_test_pgm = predictions_shuffled_pgm[train_index], predictions_shuffled_pgm[test_index]\n",
    "        \n",
    "        X_merge_train = pd.DataFrame(data=X_train_pgm, columns=column_list[2:], dtype =object)\n",
    "        y_merge_train = pd.DataFrame(data=y_train_pgm, columns= [\"category\"], dtype =object)\n",
    "        \n",
    "        X_test_pgm = pd.DataFrame(data=X_test_pgm, columns=column_list[2:] , dtype =object)\n",
    "        \n",
    "        merge_data_frame = X_merge_train\n",
    "        merge_data_frame[\"category\"] = y_merge_train\n",
    "        merge_data_frame = merge_data_frame.dropna()\n",
    "        \n",
    "        grouped = merge_data_frame.groupby('category')\n",
    "        \n",
    "        mean_vectors_classes = {}\n",
    "        count_vectors_classes = {}\n",
    "\n",
    "        for name, group in grouped:\n",
    "            group_mean_value = group.mean()\n",
    "            count_vectors_classes[name] = group.count()[\"attr1\"]\n",
    "            mean_vectors_classes[name] = [v for (k,v) in group_mean_value.items()]\n",
    "        \n",
    "        probablity_of_M = count_vectors_classes[\"M\"] / (count_vectors_classes[\"M\"] + count_vectors_classes[\"B\"])        \n",
    "        probablity_of_B = count_vectors_classes[\"B\"] / (count_vectors_classes[\"M\"] + count_vectors_classes[\"B\"])\n",
    "        \n",
    "        w,w0 = determine_coefficients(probablity_of_M,probablity_of_B,merge_data_frame,\\\n",
    "                                      mean_vectors_classes,count_vectors_classes)\n",
    "        \n",
    "        predicted_class = []\n",
    "        \n",
    "        for index,row in X_test_pgm.iterrows():\n",
    "            \n",
    "            probabiity_of_class_m = prediction(weight= w, imput_data = row.values, w0 = w0,\\\n",
    "                                              probablity_of_M = probablity_of_M, probablity_of_B = probablity_of_B,\\\n",
    "                                      mean_vectors_classes = mean_vectors_classes, count_vectors_classes = count_vectors_classes)\n",
    "            if probabiity_of_class_m > 0.5:\n",
    "                predicted_class.append(\"M\")\n",
    "            else:\n",
    "                predicted_class.append(\"B\") \n",
    "                \n",
    "        counter = 0\n",
    "        truePositive = 0\n",
    "        trueNegative = 0\n",
    "        falseNegative = 0\n",
    "        falsePositive = 0\n",
    "        \n",
    "        for value in y_test_pgm:\n",
    "            pred_value = predicted_class[counter]\n",
    "            \n",
    "            if pred_value == \"M\" and value == \"M\":\n",
    "                truePositive += 1\n",
    "            elif pred_value == \"B\" and value == \"B\":\n",
    "                trueNegative += 1\n",
    "            elif pred_value == \"B\" and value == \"M\":\n",
    "                falseNegative += 1\n",
    "            elif pred_value == \"M\" and value == \"B\" :\n",
    "                falsePositive += 1\n",
    "                \n",
    "            counter = counter + 1 \n",
    "        \n",
    "        recall = truePositive / ( truePositive + falseNegative if truePositive + falseNegative else 1) * 100\n",
    "        accuracy = (truePositive + trueNegative) / ((truePositive + falsePositive + trueNegative +falseNegative)\\\n",
    "                                                    if (truePositive + falsePositive + trueNegative +falseNegative) else 1) * 100\n",
    "        precision = truePositive / (truePositive + falsePositive if truePositive + falsePositive else 1) * 100\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        \n",
    "    print(\"Recall: %.2f\" % np.average(recall_list)+str('%'))\n",
    "    print(\"Precision: %.2f\"% np.average(precision_list)+str('%'))\n",
    "    print(\"Accuracy: %.2f\" %np.average(accuracy_list)+str('%'))\n",
    "                \n",
    "        \n",
    "perform_cross_validation(kfold_factor = 5, X_data_pgm = X_data_pgm, predictions_pgm = y_data_pgm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
