{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(k):\n",
    "    with open('multigauss.txt') as f:\n",
    "        file = f.read()\n",
    "        array_data = (file.split(\"\\n\"))\n",
    "        counter = 0\n",
    "        array_data = array_data[4:]\n",
    "        dimension_1=[]\n",
    "    \n",
    "        for data in array_data:\n",
    "            temp_array = data.strip().split(\" \")\n",
    "            if len(temp_array) >1:\n",
    "                dimension_1.append([float(temp_array[0]),float(temp_array[1])])\n",
    "            \n",
    "    dataframe = np.array([dimension_1])[0]\n",
    "        \n",
    "    n = dataframe.shape[0]\n",
    "    f = dataframe.shape[1]\n",
    "    \n",
    "    w = np.random.rand(n,k)\n",
    "    \n",
    "    pi = np.random.rand(k,1)\n",
    "    #μ is a k × f matrix containing the means of each gaussian\n",
    "    #mu = np.random.rand(k,f)\n",
    "    #Σ is an f × f × k tensor of covariance matrices. Σ(:, :, i) is the covariance of gaussian i\n",
    "   \n",
    "    mu = np.asmatrix(np.random.random((k,f)))\n",
    "    covariance = np.array([np.asmatrix(np.identity(f)) for i in range(k)])\n",
    "    \n",
    "    return dataframe, k, pi, mu, covariance, w, n, f\n",
    "\n",
    "        \n",
    "\n",
    "def expectation(X, k, pi, mu, covariance):\n",
    "    summation_gaussian = 0.0\n",
    "    data = X.copy()\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for sample in range(n):\n",
    "        summation_gaussian = 0\n",
    "        for gaussian in range(k):\n",
    "            value_of_gaussian = multivariate_normal.pdf(data[sample, :],mu[gaussian].A1,\\\n",
    "                                                        covariance[gaussian]) * pi[gaussian]\n",
    "            summation_gaussian += value_of_gaussian\n",
    "            w[sample, gaussian] = value_of_gaussian\n",
    "        \n",
    "        w[sample, :] /= summation_gaussian\n",
    "    \n",
    "    return w\n",
    "    \n",
    "def maximize_mean(X,k,w,f):\n",
    "    new_mu_gaussian = []\n",
    "    n = X.shape[0]\n",
    "    for gaussian in range(k):\n",
    "        responsibilities = w[: ,gaussian].sum()\n",
    "        \n",
    "        pi[gaussian] = 1/n * responsibilities\n",
    "        new_mu = np.zeros(f)\n",
    "        new_covariance = np.zeros((f,f))\n",
    "\n",
    "        for sample in range(n):\n",
    "            new_mu += (X[sample, :] * w[sample,gaussian])\n",
    "            \n",
    "         #   new_covariance += w[sample, gaussian] * ((X[sample, :] - mu[gaussian, :]).T *\\\n",
    "         #                                           (X[sample, :] - mu[gaussian, :]))\n",
    "              \n",
    "        new_mu_gaussian.append(new_mu / responsibilities)\n",
    "        #covariance[gaussian] = new_covariance / responsibilities\n",
    "    return new_mu_gaussian\n",
    "\n",
    "def maximize_covariance(X,k,w,mu,f):\n",
    "    new_covariance_gaussian = []\n",
    "    \n",
    "    for gaussian in range(k):\n",
    "        responsibilities = w[: ,gaussian].sum()\n",
    "        \n",
    "        pi[gaussian] = 1/n * responsibilities\n",
    "        new_mu = np.zeros(f)\n",
    "        new_covariance = np.zeros((f,f))\n",
    "\n",
    "        for sample in range(n):\n",
    "            #new_mu += (X[sample, :] * w[sample,gaussian])\n",
    "            \n",
    "            new_covariance += w[sample, gaussian] * ((X[sample, :] - mu[gaussian, :]).T *\\\n",
    "                                                    (X[sample, :] - mu[gaussian, :]))\n",
    "        \n",
    "        new_covariance_gaussian.append(  new_covariance / responsibilities )  \n",
    "       # mu[gaussian] = new_mu / responsibilities\n",
    "       # covariance[gaussian] = \n",
    "    \n",
    "    return new_covariance_gaussian\n",
    "    \n",
    "    \n",
    "\n",
    "def maximize_mixtures(k, w, X, pi, mu,n):\n",
    "    log_likelihood = 0\n",
    "    for sample in range(n):\n",
    "        summation_gaussian_value = 0\n",
    "        for gaussian in range(k):\n",
    "            summation_gaussian_value += multivariate_normal.pdf(X[sample, :],mu[gaussian, :].A1,\\\n",
    "                                                                         covariance[gaussian, :]) * pi[gaussian]\n",
    "        \n",
    "        log_likelihood += np.log(summation_gaussian_value) \n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def perform_em(X, k, pi, mu, covariance, nIter, w, n, f):\n",
    "    \n",
    "    number_iteration = 0\n",
    "    log_likelihood = 1\n",
    "    previous_log_likelihood = 0\n",
    "    \n",
    "    while((log_likelihood - previous_log_likelihood) > 1e-4):\n",
    "        number_iteration = number_iteration + 1\n",
    "        previous_log_likelihood = maximize_mixtures(k, w, X, pi, mu,n)\n",
    "        w = expectation(X, k, pi, mu, covariance)\n",
    "        new_means_gaussian = maximize_mean(X,k,w,f)\n",
    "        new_covariance = maximize_covariance(X,k,w,mu,f)\n",
    "        \n",
    "        for gaussian in range(k):\n",
    "            mu[gaussian] = new_means_gaussian[gaussian]\n",
    "            covariance[gaussian] = new_covariance[gaussian]\n",
    "        \n",
    "        log_likelihood = maximize_mixtures(k, w, X, pi, mu,n)\n",
    "        print('Iteration %d: log-likelihood is %.6f'%(number_iteration, log_likelihood))\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: log-likelihood is -6160.579772\n",
      "Iteration 2: log-likelihood is -6099.989034\n",
      "Iteration 3: log-likelihood is -6017.533444\n",
      "Iteration 4: log-likelihood is -5876.433048\n",
      "Iteration 5: log-likelihood is -5732.438933\n",
      "Iteration 6: log-likelihood is -5633.734562\n",
      "Iteration 7: log-likelihood is -5578.244178\n",
      "Iteration 8: log-likelihood is -5546.362068\n",
      "Iteration 9: log-likelihood is -5532.227796\n",
      "Iteration 10: log-likelihood is -5527.770580\n",
      "Iteration 11: log-likelihood is -5526.265606\n",
      "Iteration 12: log-likelihood is -5525.412193\n",
      "Iteration 13: log-likelihood is -5524.574611\n",
      "Iteration 14: log-likelihood is -5523.495067\n",
      "Iteration 15: log-likelihood is -5521.958606\n",
      "Iteration 16: log-likelihood is -5519.664319\n",
      "Iteration 17: log-likelihood is -5516.128044\n",
      "Iteration 18: log-likelihood is -5510.669115\n",
      "Iteration 19: log-likelihood is -5502.730594\n",
      "Iteration 20: log-likelihood is -5492.321597\n",
      "Iteration 21: log-likelihood is -5480.283724\n",
      "Iteration 22: log-likelihood is -5469.202238\n",
      "Iteration 23: log-likelihood is -5461.813935\n",
      "Iteration 24: log-likelihood is -5457.340195\n",
      "Iteration 25: log-likelihood is -5453.730490\n",
      "Iteration 26: log-likelihood is -5450.025130\n",
      "Iteration 27: log-likelihood is -5445.902576\n",
      "Iteration 28: log-likelihood is -5441.214891\n",
      "Iteration 29: log-likelihood is -5435.852086\n",
      "Iteration 30: log-likelihood is -5429.720141\n",
      "Iteration 31: log-likelihood is -5422.768277\n",
      "Iteration 32: log-likelihood is -5415.079873\n",
      "Iteration 33: log-likelihood is -5407.063326\n",
      "Iteration 34: log-likelihood is -5399.660815\n",
      "Iteration 35: log-likelihood is -5394.123037\n",
      "Iteration 36: log-likelihood is -5391.009529\n",
      "Iteration 37: log-likelihood is -5389.676857\n",
      "Iteration 38: log-likelihood is -5389.186833\n",
      "Iteration 39: log-likelihood is -5389.009570\n",
      "Iteration 40: log-likelihood is -5388.942136\n",
      "Iteration 41: log-likelihood is -5388.914945\n",
      "Iteration 42: log-likelihood is -5388.903480\n",
      "Iteration 43: log-likelihood is -5388.898500\n",
      "Iteration 44: log-likelihood is -5388.896297\n",
      "Iteration 45: log-likelihood is -5388.895311\n",
      "Iteration 46: log-likelihood is -5388.894866\n",
      "Iteration 47: log-likelihood is -5388.894665\n",
      "Iteration 48: log-likelihood is -5388.894573\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "dataframe, k, pi, mu, covariance, w, n, f = load_dataframe(k)\n",
    "perform_em(dataframe, k, pi, mu, covariance, 10, w, n, f)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
